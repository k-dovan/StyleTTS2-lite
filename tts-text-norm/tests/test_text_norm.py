import os
import pytest

os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-21-openjdk-amd64"
from cores.normalizer import TextNormalizer

text_normalizer = TextNormalizer("./exps/vncorenlp/")

# ğŸ”  Abbreviation Expansion
@pytest.mark.parametrize("input_text, expected_output", [
    ("TP.HCM Ä‘ang Ä‘á»‘i máº·t vá»›i tÃ¬nh tráº¡ng káº¹t xe nghiÃªm trá»ng.",
     "thÃ nh phá»‘ há»“ chÃ­ minh Ä‘ang Ä‘á»‘i máº·t vá»›i tÃ¬nh tráº¡ng káº¹t xe nghiÃªm trá»ng ."),
    ("Bá»™ GD&ÄT vá»«a ban hÃ nh quy cháº¿ thi tá»‘t nghiá»‡p THPT nÄƒm 2025.",
     "bá»™ giÃ¡o dá»¥c vÃ  Ä‘Ã o táº¡o vá»«a ban hÃ nh quy cháº¿ thi tá»‘t nghiá»‡p trung há»c phá»• thÃ´ng nÄƒm hai nghÃ¬n khÃ´ng trÄƒm hai mÆ°Æ¡i lÄƒm ."),
    ("Theo WHO, sá»‘ ca máº¯c COVID-19 Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m.",
     "theo vÃª kÃ©p hÃ¡t Ã´, sá»‘ ca máº¯c cÃ´ vÃ­t mÆ°á»i chÃ­n Ä‘ang cÃ³ xu hÆ°á»›ng giáº£m ."),
])
def test_abbreviation_expansion(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ“… Date Normalization
@pytest.mark.parametrize("input_text, expected_output", [
    ("Há»™i nghá»‹ diá»…n ra vÃ o ngÃ y 15/04/2025.",
     "há»™i nghá»‹ diá»…n ra vÃ o ngÃ y mÆ°á»i lÄƒm thÃ¡ng tÆ° nÄƒm hai nghÃ¬n khÃ´ng trÄƒm hai mÆ°Æ¡i lÄƒm ."),
    ("BÃ i viáº¿t Ä‘Æ°á»£c Ä‘Äƒng ngÃ y 8-3.",
     "bÃ i viáº¿t Ä‘Æ°á»£c Ä‘Äƒng ngÃ y tÃ¡m thÃ¡ng ba ."),
    ("Táº¿t NguyÃªn Ä‘Ã¡n rÆ¡i vÃ o ngÃ y 29.01.2025.",
     "táº¿t nguyÃªn Ä‘Ã¡n rÆ¡i vÃ o ngÃ y hai mÆ°Æ¡i chÃ­n thÃ¡ng má»™t nÄƒm hai nghÃ¬n khÃ´ng trÄƒm hai mÆ°Æ¡i lÄƒm ."),
])
def test_date_normalization(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# â° Time Expressions
@pytest.mark.parametrize("input_text, expected_output", [
    ("Tráº­n Ä‘áº¥u báº¯t Ä‘áº§u lÃºc 19h30.",
     "tráº­n Ä‘áº¥u báº¯t Ä‘áº§u lÃºc mÆ°á»i chÃ­n giá» ba mÆ°Æ¡i ."),
    ("Há»™i tháº£o diá»…n ra vÃ o 8 giá» sÃ¡ng mai.",
     "há»™i tháº£o diá»…n ra vÃ o tÃ¡m giá» sÃ¡ng mai ."),
    ("Chuyáº¿n bay cáº¥t cÃ¡nh lÃºc 22:45.",
     "chuyáº¿n bay cáº¥t cÃ¡nh lÃºc hai mÆ°Æ¡i hai giá» bá»‘n mÆ°Æ¡i lÄƒm phÃºt ."),
])
def test_time_expressions(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ’° Currency & Numbers
@pytest.mark.parametrize("input_text, expected_output", [
    ("GiÃ¡ xÄƒng tÄƒng lÃªn 25.000Ä‘/lÃ­t.",
     "giÃ¡ xÄƒng tÄƒng lÃªn hai mÆ°Æ¡i lÄƒm nghÃ¬n Ä‘á»“ng trÃªn lÃ­t ."),
    ("Má»©c lÆ°Æ¡ng tá»‘i thiá»ƒu lÃ  4,680,000 VNÄ.",
     "má»©c lÆ°Æ¡ng tá»‘i thiá»ƒu lÃ  bá»‘n triá»‡u sÃ¡u trÄƒm tÃ¡m mÆ°Æ¡i nghÃ¬n Ä‘á»“ng ."),
    ("GÃ³i cá»©u trá»£ trá»‹ giÃ¡ 2 tá»· Ä‘á»“ng.",
     "gÃ³i cá»©u trá»£ trá»‹ giÃ¡ hai tá»· Ä‘á»“ng ."),
])
def test_currency_and_numbers(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ“ Units & Measurements
@pytest.mark.parametrize("input_text, expected_output", [
    ("SÃ¢n bay má»›i cÃ³ diá»‡n tÃ­ch 120ha.",
     "sÃ¢n bay má»›i cÃ³ diá»‡n tÃ­ch má»™t trÄƒm hai mÆ°Æ¡i hecta ."),
    ("Tráº» em nÃªn uá»‘ng 500ml sá»¯a má»—i ngÃ y.",
     "tráº» em nÃªn uá»‘ng nÄƒm trÄƒm mi li lÃ­t sá»¯a má»—i ngÃ y ."),
    ("Anh áº¥y cao 1m75.",
     "anh áº¥y cao má»™t mÃ©t báº£y mÆ°Æ¡i lÄƒm ."),
])
def test_units_and_measurements(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ”¢ General Numbers
@pytest.mark.parametrize("input_text, expected_output", [
    ("DÃ¢n sá»‘ Viá»‡t Nam nÄƒm 2025 dá»± kiáº¿n Ä‘áº¡t 105 triá»‡u ngÆ°á»i.",
     "dÃ¢n sá»‘ viá»‡t nam nÄƒm hai nghÃ¬n khÃ´ng trÄƒm hai mÆ°Æ¡i lÄƒm dá»± kiáº¿n Ä‘áº¡t má»™t trÄƒm láº» nÄƒm triá»‡u ngÆ°á»i ."),
    ("Tá»· lá»‡ tháº¥t nghiá»‡p giáº£m cÃ²n 3.5%.",
     "tá»· lá»‡ tháº¥t nghiá»‡p giáº£m cÃ²n ba pháº©y nÄƒm pháº§n trÄƒm ."),
    ("CÃ³ hÆ¡n 12.345 ca máº¯c má»›i Ä‘Æ°á»£c ghi nháº­n.",
     "cÃ³ hÆ¡n mÆ°á»i hai nghÃ¬n ba trÄƒm bá»‘n mÆ°Æ¡i lÄƒm ca máº¯c má»›i Ä‘Æ°á»£c ghi nháº­n ."),
])
def test_general_numbers(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ§¾ Common News Phrases
@pytest.mark.parametrize("input_text, expected_output", [
    ("Theo ghi nháº­n cá»§a PV, tÃ¬nh tráº¡ng ngáº­p kÃ©o dÃ i.",
     "theo ghi nháº­n cá»§a phÃ³ng viÃªn, tÃ¬nh tráº¡ng ngáº­p kÃ©o dÃ i ."),
    ("ChÃ­nh phá»§ sáº½ há»p vÃ o Ä‘áº§u tuáº§n tá»›i Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.",
     "chÃ­nh phá»§ sáº½ há»p vÃ o Ä‘áº§u tuáº§n tá»›i Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh ."),
    ("Thá»§ tÆ°á»›ng phÃ¡t biá»ƒu táº¡i lá»… khai máº¡c diá»…n ra á»Ÿ HÃ  Ná»™i.",
     "thá»§ tÆ°á»›ng phÃ¡t biá»ƒu táº¡i lá»… khai máº¡c diá»…n ra á»Ÿ hÃ  ná»™i ."),
])
def test_common_phrases(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸŒ Websites & Links
@pytest.mark.parametrize("input_text, expected_output", [
    ("Äá»™c giáº£ cÃ³ thá»ƒ xem thÃªm táº¡i www.vietnamnews.vn.",
     "Ä‘á»™c giáº£ cÃ³ thá»ƒ xem thÃªm táº¡i www cháº¥m vietnamnews cháº¥m v n ."),
    ("Tham kháº£o thÃªm thÃ´ng tin qua Ä‘á»‹a chá»‰ https://moet.gov.vn.",
     "tham kháº£o thÃªm thÃ´ng tin qua Ä‘á»‹a chá»‰ h t t p s hai cháº¥m gáº¡ch gáº¡ch moet cháº¥m g o v cháº¥m v n ."),
])
def test_web_links(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ§  Special Characters & Slang
@pytest.mark.parametrize("input_text, expected_output", [
    ("Tin nÃ³ng!!!", "tin nÃ³ng ."),
    ("Kháº©n cáº¥p: Cáº£nh bÃ¡o mÆ°a lá»›n.", "kháº©n cáº¥p: cáº£nh bÃ¡o mÆ°a lá»›n ."),
    ("GiÃ¡ Ä‘iá»‡n tÄƒng â€œchÃ³ng máº·tâ€.", "giÃ¡ Ä‘iá»‡n tÄƒng chÃ³ng máº·t ."),
])
def test_special_characters(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ‡»ğŸ‡³ Vietnamese Names & Locations
@pytest.mark.parametrize("input_text, expected_output", [
    ("Ã”ng Nguyá»…n VÄƒn A Ä‘Ã£ phÃ¡t biá»ƒu táº¡i buá»•i lá»….",
     "Ã´ng nguyá»…n vÄƒn a Ä‘Ã£ phÃ¡t biá»ƒu táº¡i buá»•i lá»… ."),
    ("Cáº§u Cáº§n ThÆ¡ lÃ  cÃ´ng trÃ¬nh tiÃªu biá»ƒu á»Ÿ miá»n TÃ¢y.",
     "cáº§u cáº§n thÆ¡ lÃ  cÃ´ng trÃ¬nh tiÃªu biá»ƒu á»Ÿ miá»n tÃ¢y ."),
])
def test_names_and_locations(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ§ª Mixed Context & Edge Cases
@pytest.mark.parametrize("input_text, expected_output", [
    ("Thá»i tiáº¿t hÃ´m nay táº¡i TP.HCM: 32Â°C, Ä‘á»™ áº©m 75%.",
     "thá»i tiáº¿t hÃ´m nay táº¡i thÃ nh phá»‘ há»“ chÃ­ minh: ba mÆ°Æ¡i hai Ä‘á»™ c, Ä‘á»™ áº©m báº£y mÆ°Æ¡i lÄƒm pháº§n trÄƒm ."),
    ("Ã”ng áº¥y náº·ng 75kg vÃ  cao 1m80.",
     "Ã´ng áº¥y náº·ng báº£y mÆ°Æ¡i lÄƒm ki lÃ´ gam vÃ  cao má»™t mÃ©t tÃ¡m mÆ°Æ¡i ."),
])
def test_mixed_edge_cases(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output

# ğŸ§ª Multi-Sentence Test Cases
@pytest.mark.parametrize("input_text, expected_output", [
    ("TP.HCM Ä‘ang mÆ°a lá»›n. NgÆ°á»i dÃ¢n nÃªn háº¡n cháº¿ ra Ä‘Æ°á»ng.",
     "thÃ nh phá»‘ há»“ chÃ­ minh Ä‘ang mÆ°a lá»›n . ngÆ°á»i dÃ¢n nÃªn háº¡n cháº¿ ra Ä‘Æ°á»ng ."),
    ("Há»™i nghá»‹ sáº½ diá»…n ra vÃ o ngÃ y 20/4. Thá»i gian báº¯t Ä‘áº§u lÃºc 9h sÃ¡ng.",
     "há»™i nghá»‹ sáº½ diá»…n ra vÃ o ngÃ y hai mÆ°Æ¡i thÃ¡ng tÆ° . thá»i gian báº¯t Ä‘áº§u lÃºc chÃ­n giá» sÃ¡ng ."),
    ("GiÃ¡ vÃ ng hÃ´m nay tÄƒng máº¡nh. Má»©c giÃ¡ hiá»‡n táº¡i lÃ  75.000.000Ä‘/lÆ°á»£ng.",
     "giÃ¡ vÃ ng hÃ´m nay tÄƒng máº¡nh . má»©c giÃ¡ hiá»‡n táº¡i lÃ  báº£y mÆ°Æ¡i lÄƒm triá»‡u Ä‘á»“ng má»™t lÆ°á»£ng ."),
    ("Website www.tuoitre.vn cáº­p nháº­t tin nhanh. Má»i Ä‘á»™c giáº£ Ä‘Ã³n Ä‘á»c.",
     "website www cháº¥m tuoitre cháº¥m v n cáº­p nháº­t tin nhanh . má»i Ä‘á»™c giáº£ Ä‘Ã³n Ä‘á»c ."),
    ("Tráº­n Ä‘áº¥u báº¯t Ä‘áº§u lÃºc 19h30. Dá»± kiáº¿n káº¿t thÃºc lÃºc 21h45.",
     "tráº­n Ä‘áº¥u báº¯t Ä‘áº§u lÃºc mÆ°á»i chÃ­n giá» ba mÆ°Æ¡i phÃºt . dá»± kiáº¿n káº¿t thÃºc lÃºc hai mÆ°Æ¡i má»™t giá» bá»‘n mÆ°Æ¡i lÄƒm phÃºt ."),
    ("BÃ© náº·ng 3.5kg khi sinh. Hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c 6 thÃ¡ng tuá»•i.",
     "bÃ© náº·ng ba pháº©y nÄƒm ki lÃ´ gam khi sinh . hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c sÃ¡u thÃ¡ng tuá»•i ."),
    ("Theo bÃ¡o cÃ¡o, tá»· lá»‡ tháº¥t nghiá»‡p lÃ  3.7%. Con sá»‘ nÃ y giáº£m nháº¹ so vá»›i quÃ½ trÆ°á»›c.",
     "theo bÃ¡o cÃ¡o , tá»· lá»‡ tháº¥t nghiá»‡p lÃ  ba pháº©y báº£y pháº§n trÄƒm . con sá»‘ nÃ y giáº£m nháº¹ so vá»›i quÃ½ trÆ°á»›c ."),
    ("Bá»™ GD&ÄT vá»«a cÃ´ng bá»‘ lá»‹ch thi. Ká»³ thi sáº½ báº¯t Ä‘áº§u tá»« ngÃ y 1/6.",
     "bá»™ giÃ¡o dá»¥c vÃ  Ä‘Ã o táº¡o vá»«a cÃ´ng bá»‘ lá»‹ch thi . ká»³ thi sáº½ báº¯t Ä‘áº§u tá»« ngÃ y má»™t thÃ¡ng sÃ¡u ."),
    ("Anh áº¥y cao 1m80. CÃ¢n náº·ng 80kg.",
     "anh áº¥y cao má»™t mÃ©t tÃ¡m mÆ°Æ¡i . cÃ¢n náº·ng tÃ¡m mÆ°Æ¡i ki lÃ´ gam ."),
    ("Nhiá»‡t Ä‘á»™ á»Ÿ HÃ  Ná»™i lÃ  32Â°C. Trong khi Ä‘Ã³, TP.HCM lÃ  34Â°C.",
     "nhiá»‡t Ä‘á»™ á»Ÿ hÃ  ná»™i lÃ  ba mÆ°Æ¡i hai Ä‘á»™ c . trong khi Ä‘Ã³ , thÃ nh phá»‘ há»“ chÃ­ minh lÃ  ba mÆ°Æ¡i bá»‘n Ä‘á»™ c ."),
])
def test_multi_sentence_normalization(input_text, expected_output):
    assert ' '.join(text_normalizer(input_text)) == expected_output
